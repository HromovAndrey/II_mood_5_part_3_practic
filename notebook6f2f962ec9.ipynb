{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/andrey36912/notebook6f2f962ec9?scriptVersionId=192999350\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import torch\nfrom torchvision import datasets, transforms\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"execution":{"iopub.status.busy":"2024-08-17T17:30:21.499261Z","iopub.execute_input":"2024-08-17T17:30:21.499911Z","iopub.status.idle":"2024-08-17T17:30:21.507252Z","shell.execute_reply.started":"2024-08-17T17:30:21.499857Z","shell.execute_reply":"2024-08-17T17:30:21.505682Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"data_dir = '/kaggle/input/leukemia-classification/C-NMC_Leukemia/training_data/fold_0'\n\n\ndataset = datasets.ImageFolder(root=data_dir)","metadata":{"execution":{"iopub.status.busy":"2024-08-17T17:30:21.509785Z","iopub.execute_input":"2024-08-17T17:30:21.51025Z","iopub.status.idle":"2024-08-17T17:30:22.060861Z","shell.execute_reply.started":"2024-08-17T17:30:21.51019Z","shell.execute_reply":"2024-08-17T17:30:22.059497Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"data_dir = '/kaggle/input/leukemia-classification/C-NMC_Leukemia/training_data/fold_1'\ndataset1 = datasets.ImageFolder(root=data_dir)","metadata":{"execution":{"iopub.status.busy":"2024-08-17T17:30:22.062425Z","iopub.execute_input":"2024-08-17T17:30:22.062791Z","iopub.status.idle":"2024-08-17T17:30:22.59467Z","shell.execute_reply.started":"2024-08-17T17:30:22.06276Z","shell.execute_reply":"2024-08-17T17:30:22.593316Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"data_dir = '/kaggle/input/leukemia-classification/C-NMC_Leukemia/training_data/fold_2'\ndataset2 = datasets.ImageFolder(root=data_dir)","metadata":{"execution":{"iopub.status.busy":"2024-08-17T17:30:22.596558Z","iopub.execute_input":"2024-08-17T17:30:22.596883Z","iopub.status.idle":"2024-08-17T17:30:23.103898Z","shell.execute_reply.started":"2024-08-17T17:30:22.596856Z","shell.execute_reply":"2024-08-17T17:30:23.102672Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import ConcatDataset\ndataset = ConcatDataset([dataset, dataset1, dataset2])\nlen(dataset)","metadata":{"execution":{"iopub.status.busy":"2024-08-17T17:30:23.106565Z","iopub.execute_input":"2024-08-17T17:30:23.106997Z","iopub.status.idle":"2024-08-17T17:30:23.116253Z","shell.execute_reply.started":"2024-08-17T17:30:23.106934Z","shell.execute_reply":"2024-08-17T17:30:23.115017Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"10661"},"metadata":{}}]},{"cell_type":"code","source":"classes = dataset.datasets[0].classes  \nnum_classes = len(classes)\nprint(classes)\nprint(f'Number of classes: {num_classes}')","metadata":{"execution":{"iopub.status.busy":"2024-08-17T17:30:23.117669Z","iopub.execute_input":"2024-08-17T17:30:23.118148Z","iopub.status.idle":"2024-08-17T17:30:23.129483Z","shell.execute_reply.started":"2024-08-17T17:30:23.11811Z","shell.execute_reply":"2024-08-17T17:30:23.12814Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"['all', 'hem']\nNumber of classes: 2\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch.utils.data import random_split\n\ntrain_ratio = 0.8\n\ntrain_data, test_data = random_split(dataset, [train_ratio, 1-train_ratio])","metadata":{"execution":{"iopub.status.busy":"2024-08-17T17:30:23.131072Z","iopub.execute_input":"2024-08-17T17:30:23.131532Z","iopub.status.idle":"2024-08-17T17:30:23.143905Z","shell.execute_reply.started":"2024-08-17T17:30:23.131499Z","shell.execute_reply":"2024-08-17T17:30:23.142728Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.Resize((224, 224)), \n    transforms.RandomHorizontalFlip(p=0.5), \n    transforms.ToTensor(), \n    transforms.Normalize(mean=[0.3517, 0.3557, 0.3570],\n                         std=[0.2325, 0.2347, 0.2353]) \n])\n\ntest_transform = transforms.Compose([\n    transforms.Resize((224, 224)), \n    transforms.ToTensor(), \n    transforms.Normalize(mean=[0.3517, 0.3557, 0.3570],\n                         std=[0.2325, 0.2347, 0.2353]) \n])\n\n\nclass TransformDataset(torch.utils.data.Dataset):\n    def __init__(self, subset, transform=None):\n        self.subset = subset\n        self.transform = transform\n        \n    def __getitem__(self, index):\n        x, y = self.subset[index]\n        if self.transform:\n            x = self.transform(x)\n        return x, y\n        \n    def __len__(self):\n        return len(self.subset)\n\n    \ntrain_data = TransformDataset(train_data, transform = train_transform)\ntest_data = TransformDataset(test_data, transform = test_transform)","metadata":{"execution":{"iopub.status.busy":"2024-08-17T17:30:23.145441Z","iopub.execute_input":"2024-08-17T17:30:23.145833Z","iopub.status.idle":"2024-08-17T17:30:23.157328Z","shell.execute_reply.started":"2024-08-17T17:30:23.145795Z","shell.execute_reply":"2024-08-17T17:30:23.156252Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"means = []\nstds = []\nfor img, _ in train_data:\n    means.append(torch.mean(img, [1, 2]).tolist())\n    stds.append(torch.std(img, [1, 2]).tolist())\n\nmean = torch.mean(torch.tensor(means), [0])\nstd = torch.mean(torch.tensor(stds), [0])\n\nmean, std","metadata":{"execution":{"iopub.status.busy":"2024-08-17T17:35:00.32735Z","iopub.execute_input":"2024-08-17T17:35:00.327953Z","iopub.status.idle":"2024-08-17T17:37:10.656251Z","shell.execute_reply.started":"2024-08-17T17:35:00.327898Z","shell.execute_reply":"2024-08-17T17:37:10.655036Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"(tensor([-1.3186, -1.4322, -1.2980]), tensor([0.4340, 0.1911, 0.4888]))"},"metadata":{}}]},{"cell_type":"code","source":"img.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-17T17:38:23.092254Z","iopub.execute_input":"2024-08-17T17:38:23.092769Z","iopub.status.idle":"2024-08-17T17:38:23.102222Z","shell.execute_reply.started":"2024-08-17T17:38:23.092729Z","shell.execute_reply":"2024-08-17T17:38:23.10054Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"torch.Size([3, 224, 224])"},"metadata":{}}]},{"cell_type":"code","source":"batch_size = 256\ntrain_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=batch_size)\ntest_loader = torch.utils.data.DataLoader(test_data, shuffle=True, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-08-17T17:40:15.770112Z","iopub.execute_input":"2024-08-17T17:40:15.770631Z","iopub.status.idle":"2024-08-17T17:40:15.77724Z","shell.execute_reply.started":"2024-08-17T17:40:15.770589Z","shell.execute_reply":"2024-08-17T17:40:15.775857Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"from torchvision import models\n\nvgg19 = models.vgg19_bn(pretrained=True)\nvgg19","metadata":{"execution":{"iopub.status.busy":"2024-08-17T17:42:45.36173Z","iopub.execute_input":"2024-08-17T17:42:45.362312Z","iopub.status.idle":"2024-08-17T17:43:15.03152Z","shell.execute_reply.started":"2024-08-17T17:42:45.362272Z","shell.execute_reply":"2024-08-17T17:43:15.029469Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_BN_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_BN_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/vgg19_bn-c79401a0.pth\" to /root/.cache/torch/hub/checkpoints/vgg19_bn-c79401a0.pth\n100%|██████████| 548M/548M [00:26<00:00, 21.8MB/s]   \n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"VGG(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU(inplace=True)\n    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (9): ReLU(inplace=True)\n    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (12): ReLU(inplace=True)\n    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (16): ReLU(inplace=True)\n    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (19): ReLU(inplace=True)\n    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (22): ReLU(inplace=True)\n    (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (25): ReLU(inplace=True)\n    (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (29): ReLU(inplace=True)\n    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (32): ReLU(inplace=True)\n    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (35): ReLU(inplace=True)\n    (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (38): ReLU(inplace=True)\n    (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (42): ReLU(inplace=True)\n    (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (45): ReLU(inplace=True)\n    (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (48): ReLU(inplace=True)\n    (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (51): ReLU(inplace=True)\n    (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n  (classifier): Sequential(\n    (0): Linear(in_features=25088, out_features=4096, bias=True)\n    (1): ReLU(inplace=True)\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Linear(in_features=4096, out_features=4096, bias=True)\n    (4): ReLU(inplace=True)\n    (5): Dropout(p=0.5, inplace=False)\n    (6): Linear(in_features=4096, out_features=1000, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"from torch import nn\nimport torch.nn.functional as F\nimport numpy as np\n\n\nclass TransferLearningClassifier(nn.Module):\n    def __init__(self, num_classes=10):\n        super().__init__()\n\n        vgg = models.vgg19_bn(pretrained=True)\n        \n        # від'єднання градієнтів\n        for param in vgg.parameters():\n            param.requires_grad = False\n        \n        # кількість нейронів на виході\n        in_features = vgg.classifier[0].in_features\n        \n        # деактивація останнього шару\n        vgg.classifier = nn.Identity()\n        \n        # створення потрібних шарів\n        self.feature_extractor = vgg\n        \n        self.dropout = nn.Dropout(0.2)\n        self.linear = nn.Linear(in_features, num_classes)\n        \n\n    def forward(self, x):\n        out = self.feature_extractor(x) # (batch, in_features)\n        \n        out = self.dropout(out)\n        out = self.linear(out)\n        \n        return out\n\n\n    def predict(self, X, device='cpu'):\n        X = torch.FloatTensor(np.array(X)).to(device)\n\n        with torch.no_grad():\n            y_pred = F.softmax(self.forward(X), dim=-1)\n\n        return y_pred.cpu().numpy()\n\n\nmodel = TransferLearningClassifier(len(dataset.classes)).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-08-17T17:43:25.324218Z","iopub.execute_input":"2024-08-17T17:43:25.324809Z","iopub.status.idle":"2024-08-17T17:43:25.655742Z","shell.execute_reply.started":"2024-08-17T17:43:25.324767Z","shell.execute_reply":"2024-08-17T17:43:25.654201Z"},"trusted":true},"execution_count":23,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[23], line 47\u001b[0m\n\u001b[1;32m     42\u001b[0m             y_pred \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(X), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     44\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m y_pred\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m---> 47\u001b[0m model \u001b[38;5;241m=\u001b[39m TransferLearningClassifier(\u001b[38;5;28mlen\u001b[39m(\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses\u001b[49m))\u001b[38;5;241m.\u001b[39mto(device)\n","\u001b[0;31mAttributeError\u001b[0m: 'ConcatDataset' object has no attribute 'classes'"],"ename":"AttributeError","evalue":"'ConcatDataset' object has no attribute 'classes'","output_type":"error"}]}]}