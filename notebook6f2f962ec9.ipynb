{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1449674,"sourceType":"datasetVersion","datasetId":849724}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/andrey36912/notebook6f2f962ec9?scriptVersionId=193087771\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import torch\nfrom torchvision import datasets, transforms\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"execution":{"iopub.status.busy":"2024-08-18T14:38:25.979051Z","iopub.execute_input":"2024-08-18T14:38:25.979432Z","iopub.status.idle":"2024-08-18T14:38:25.985275Z","shell.execute_reply.started":"2024-08-18T14:38:25.979405Z","shell.execute_reply":"2024-08-18T14:38:25.983815Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"data_dir = '/kaggle/input/leukemia-classification/C-NMC_Leukemia/training_data/fold_0'\n\n\ndataset = datasets.ImageFolder(root=data_dir)","metadata":{"execution":{"iopub.status.busy":"2024-08-18T14:38:26.023055Z","iopub.execute_input":"2024-08-18T14:38:26.023466Z","iopub.status.idle":"2024-08-18T14:38:27.538753Z","shell.execute_reply.started":"2024-08-18T14:38:26.023425Z","shell.execute_reply":"2024-08-18T14:38:27.53782Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"data_dir = '/kaggle/input/leukemia-classification/C-NMC_Leukemia/training_data/fold_1'\ndataset1 = datasets.ImageFolder(root=data_dir)","metadata":{"execution":{"iopub.status.busy":"2024-08-18T14:38:27.54088Z","iopub.execute_input":"2024-08-18T14:38:27.541332Z","iopub.status.idle":"2024-08-18T14:38:29.065269Z","shell.execute_reply.started":"2024-08-18T14:38:27.541293Z","shell.execute_reply":"2024-08-18T14:38:29.064259Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"data_dir = '/kaggle/input/leukemia-classification/C-NMC_Leukemia/training_data/fold_2'\ndataset2 = datasets.ImageFolder(root=data_dir)","metadata":{"execution":{"iopub.status.busy":"2024-08-18T14:38:29.066513Z","iopub.execute_input":"2024-08-18T14:38:29.066834Z","iopub.status.idle":"2024-08-18T14:38:30.467283Z","shell.execute_reply.started":"2024-08-18T14:38:29.066807Z","shell.execute_reply":"2024-08-18T14:38:30.466144Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import ConcatDataset\ndataset = ConcatDataset([dataset, dataset1, dataset2])\nlen(dataset)","metadata":{"execution":{"iopub.status.busy":"2024-08-18T14:38:30.469707Z","iopub.execute_input":"2024-08-18T14:38:30.470094Z","iopub.status.idle":"2024-08-18T14:38:30.47732Z","shell.execute_reply.started":"2024-08-18T14:38:30.470062Z","shell.execute_reply":"2024-08-18T14:38:30.476294Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"10661"},"metadata":{}}]},{"cell_type":"code","source":"classes = dataset.datasets[0].classes\nnum_classes = len(classes)","metadata":{"execution":{"iopub.status.busy":"2024-08-18T14:38:30.478603Z","iopub.execute_input":"2024-08-18T14:38:30.478988Z","iopub.status.idle":"2024-08-18T14:38:30.488511Z","shell.execute_reply.started":"2024-08-18T14:38:30.478959Z","shell.execute_reply":"2024-08-18T14:38:30.487313Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"model = TransferLearningClassifier(num_classes).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-08-18T14:38:30.490054Z","iopub.execute_input":"2024-08-18T14:38:30.490406Z","iopub.status.idle":"2024-08-18T14:38:30.531687Z","shell.execute_reply.started":"2024-08-18T14:38:30.490376Z","shell.execute_reply":"2024-08-18T14:38:30.529154Z"},"trusted":true},"execution_count":14,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mTransferLearningClassifier\u001b[49m(num_classes)\u001b[38;5;241m.\u001b[39mto(device)\n","\u001b[0;31mNameError\u001b[0m: name 'TransferLearningClassifier' is not defined"],"ename":"NameError","evalue":"name 'TransferLearningClassifier' is not defined","output_type":"error"}]},{"cell_type":"code","source":"from torch.utils.data import random_split\n\ntrain_ratio = 0.8\n\ntrain_data, test_data = random_split(dataset, [train_ratio, 1-train_ratio])","metadata":{"execution":{"iopub.status.busy":"2024-08-18T14:38:30.533169Z","iopub.status.idle":"2024-08-18T14:38:30.53458Z","shell.execute_reply.started":"2024-08-18T14:38:30.534275Z","shell.execute_reply":"2024-08-18T14:38:30.534302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.Resize((224, 224)), \n    transforms.RandomHorizontalFlip(p=0.5), \n    transforms.ToTensor(), \n    transforms.Normalize(mean=[0.3517, 0.3557, 0.3570],\n                         std=[0.2325, 0.2347, 0.2353]) \n])\n\ntest_transform = transforms.Compose([\n    transforms.Resize((224, 224)), \n    transforms.ToTensor(), \n    transforms.Normalize(mean=[0.3517, 0.3557, 0.3570],\n                         std=[0.2325, 0.2347, 0.2353]) \n])\n\n\nclass TransformDataset(torch.utils.data.Dataset):\n    def __init__(self, subset, transform=None):\n        self.subset = subset\n        self.transform = transform\n        \n    def __getitem__(self, index):\n        x, y = self.subset[index]\n        if self.transform:\n            x = self.transform(x)\n        return x, y\n        \n    def __len__(self):\n        return len(self.subset)\n\n    \ntrain_data = TransformDataset(train_data, transform = train_transform)\ntest_data = TransformDataset(test_data, transform = test_transform)","metadata":{"execution":{"iopub.status.busy":"2024-08-18T14:38:30.536143Z","iopub.status.idle":"2024-08-18T14:38:30.536776Z","shell.execute_reply.started":"2024-08-18T14:38:30.536495Z","shell.execute_reply":"2024-08-18T14:38:30.53652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"means = []\nstds = []\nfor img, _ in train_data:\n    means.append(torch.mean(img, [1, 2]).tolist())\n    stds.append(torch.std(img, [1, 2]).tolist())\n\nmean = torch.mean(torch.tensor(means), [0])\nstd = torch.mean(torch.tensor(stds), [0])\n\nmean, std","metadata":{"execution":{"iopub.status.busy":"2024-08-18T14:38:30.53829Z","iopub.status.idle":"2024-08-18T14:38:30.538817Z","shell.execute_reply.started":"2024-08-18T14:38:30.538543Z","shell.execute_reply":"2024-08-18T14:38:30.538566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-18T14:38:30.540436Z","iopub.status.idle":"2024-08-18T14:38:30.540973Z","shell.execute_reply.started":"2024-08-18T14:38:30.540683Z","shell.execute_reply":"2024-08-18T14:38:30.540704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 256\ntrain_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=batch_size)\ntest_loader = torch.utils.data.DataLoader(test_data, shuffle=True, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-08-18T14:38:30.542491Z","iopub.status.idle":"2024-08-18T14:38:30.542861Z","shell.execute_reply.started":"2024-08-18T14:38:30.542681Z","shell.execute_reply":"2024-08-18T14:38:30.542696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchvision import models\n\nvgg19 = models.vgg19_bn(pretrained=True)\nvgg19","metadata":{"execution":{"iopub.status.busy":"2024-08-18T14:38:30.544199Z","iopub.status.idle":"2024-08-18T14:38:30.5446Z","shell.execute_reply.started":"2024-08-18T14:38:30.544394Z","shell.execute_reply":"2024-08-18T14:38:30.544411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch import nn\nimport torch.nn.functional as F\nimport numpy as np\n\nclass TransferLearningClassifier(nn.Module):\n    def __init__(self, num_classes=10):\n        super().__init__()\n\n        vgg = models.vgg19_bn(pretrained=True)\n        \n        # Замораживание градиентов\n        for param in vgg.parameters():\n            param.requires_grad = False\n        \n        # Количество выходных нейронов\n        in_features = vgg.classifier[0].in_features\n        \n        # Удаление последнего слоя\n        vgg.classifier = nn.Identity()\n        \n        # Создание новых слоев\n        self.feature_extractor = vgg\n        self.dropout = nn.Dropout(0.2)\n        self.linear = nn.Linear(in_features, num_classes)\n        \n    def forward(self, x):\n        out = self.feature_extractor(x) # (batch, in_features)\n        out = self.dropout(out)\n        out = self.linear(out)\n        return out\n\n    def predict(self, X, device='cpu'):\n        X = torch.FloatTensor(np.array(X)).to(device)\n        with torch.no_grad():\n            y_pred = F.softmax(self.forward(X), dim=-1)\n        return y_pred.cpu().numpy()\n\nmodel = TransferLearningClassifier(num_classes).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-08-18T14:38:30.547604Z","iopub.status.idle":"2024-08-18T14:38:30.54805Z","shell.execute_reply.started":"2024-08-18T14:38:30.547819Z","shell.execute_reply":"2024-08-18T14:38:30.547836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install torchsummary","metadata":{"execution":{"iopub.status.busy":"2024-08-18T14:38:30.549123Z","iopub.status.idle":"2024-08-18T14:38:30.54952Z","shell.execute_reply.started":"2024-08-18T14:38:30.549327Z","shell.execute_reply":"2024-08-18T14:38:30.549345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchsummary import summary\nmodel = TransferLearningClassifier(num_classes).to(device)\nsummary(model, input_size=(3, 224, 224))\n","metadata":{"execution":{"iopub.status.busy":"2024-08-18T14:38:30.551029Z","iopub.status.idle":"2024-08-18T14:38:30.551415Z","shell.execute_reply.started":"2024-08-18T14:38:30.551228Z","shell.execute_reply":"2024-08-18T14:38:30.551244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\n\ndef train(model, optimizer, loss_fn, train_dl, val_dl,\n          metrics=None, metrics_name=None, epochs=20, device='cpu', task='regression'):\n   \n\n    print('train() called: model=%s, opt=%s(lr=%f), epochs=%d, device=%s\\n' % \\\n          (type(model).__name__, type(optimizer).__name__,\n           optimizer.param_groups[0]['lr'], epochs, device))\n\n    metrics = metrics if metrics else []\n    metrics_name = metrics_name if metrics_name else [metric.__name__ for metric in metrics]\n\n    history = {} \n    history['loss'] = []\n    history['val_loss'] = []\n    for name in metrics_name:\n        history[name] = []\n        history[f'val_{name}'] = []\n\n    start_time_train = time.time()\n\n    for epoch in range(epochs):\n\n       \n        start_time_epoch = time.time()\n\n        model.train()\n        history_train = {name: 0 for name in ['loss']+metrics_name}\n\n        for batch in train_dl:\n            x    = batch[0].to(device)\n            y    = batch[1].to(device)\n            y_pred = model(x)\n            loss = loss_fn(y_pred, y)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            y_pred = y_pred.detach().cpu().numpy()\n            y = y.detach().cpu().numpy()\n\n\n            history_train['loss'] += loss.item() * x.size(0)\n            for name, func in zip(metrics_name, metrics):\n                try:\n                    history_train[name] += func(y, y_pred) * x.size(0)\n                except:\n                    if task == 'binary': y_pred_ = y_pred.round()\n                    elif task == 'multiclass': y_pred_ = y_pred.argmax(axis=-1)\n                    history_train[name] += func(y, y_pred_) * x.size(0)\n\n        for name in history_train:\n            history_train[name] /= len(train_dl.dataset)\n\n\n       \n        model.eval()\n        history_val = {'val_' + name: 0 for name in metrics_name+['loss']}\n\n        with torch.no_grad():\n            for batch in val_dl:\n                x    = batch[0].to(device)\n                y    = batch[1].to(device)\n                y_pred = model(x)\n                loss = loss_fn(y_pred, y)\n\n                y_pred = y_pred.cpu().numpy()\n                y = y.cpu().numpy()\n\n                history_val['val_loss'] += loss.item() * x.size(0)\n                for name, func in zip(metrics_name, metrics):\n                    try:\n                        history_val['val_'+name] += func(y, y_pred) * x.size(0)\n                    except:\n                        if task == 'binary': y_pred_ = y_pred.round()\n                        elif task == 'multiclass': y_pred_ = y_pred.argmax(axis=-1)\n\n                        history_val['val_'+name] += func(y, y_pred_) * x.size(0)\n\n        for name in history_val:\n            history_val[name] /= len(val_dl.dataset)\n\n       \n\n        end_time_epoch = time.time()\n\n        for name in history_train:\n            history[name].append(history_train[name])\n            history['val_'+name].append(history_val['val_'+name])\n\n        total_time_epoch = end_time_epoch - start_time_epoch\n\n        print(f'Epoch {epoch+1:4d} {total_time_epoch:4.0f}sec', end='\\t')\n        for name in history_train:\n            print(f'{name}: {history[name][-1]:10.3g}', end='\\t')\n            print(f\"val_{name}: {history['val_'+name][-1]:10.3g}\", end='\\t')\n        print()\n\n\n\n    end_time_train       = time.time()\n    total_time_train     = end_time_train - start_time_train\n    print()\n    print('Time total:     %5.2f sec' % (total_time_train))\n\n    return history","metadata":{"execution":{"iopub.status.busy":"2024-08-18T14:38:30.552656Z","iopub.status.idle":"2024-08-18T14:38:30.553067Z","shell.execute_reply.started":"2024-08-18T14:38:30.552846Z","shell.execute_reply":"2024-08-18T14:38:30.552862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_fn = nn.CrossEntropyLoss()\n\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)","metadata":{"execution":{"iopub.status.busy":"2024-08-18T14:38:30.555188Z","iopub.status.idle":"2024-08-18T14:38:30.555561Z","shell.execute_reply.started":"2024-08-18T14:38:30.555377Z","shell.execute_reply":"2024-08-18T14:38:30.555392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\nhistory = train(model, optimizer, loss_fn, train_loader, test_loader,\n                epochs=50,\n                metrics=[accuracy_score],\n                device=device,\n                task='multiclass')","metadata":{"execution":{"iopub.status.busy":"2024-08-18T14:38:30.556745Z","iopub.status.idle":"2024-08-18T14:38:30.557163Z","shell.execute_reply.started":"2024-08-18T14:38:30.55697Z","shell.execute_reply":"2024-08-18T14:38:30.556988Z"},"trusted":true},"execution_count":null,"outputs":[]}]}